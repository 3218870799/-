确定具体服务还是响应，确定是上下游问题还是升级或调整带来的问题；

也有可能是某个实例的问题，某台机器性能不太行；

在看机器的CPU，IO，内存

Arthas分析线程状态，是否是锁的问题，死循环问题

线程上下文切换问题，使用pidstat看下切换频率；

如果内存异常，调整下JVM内存，GC问题；

IO问题出现的比较少



# 1：数据库问题

这几乎是发生频率最高的，

主要从五个方面优化数据库问题：

- 升级数据库配置，能用钱解决最好，见效快；                    
- 优化数据库参数，最大限度利用硬件，比如innodb_buffer_pool_size的调整
- 加索引，利用索引将查询的效率提上去，这块可以借用云厂商的数据库诊断工具，

- 优化SQL， 复杂SQL拆分、去除不必要的语句等

- 在架构上做一些优化，按照2/8原则来讲，80%的请求都是读操作，可以通过增加读库的方式来提升读的吞吐量，也就是常说的读写分离，做了读写分离以后，报表查询只会导致读库cpu 100%，读库一般可以挂多个，可以缓解原来RDS单库的压力，如何接入读写分离也是个需要重点考虑的点： 

 

# 2：fullgc频繁

- cpu被某个大任务占满，导致其他服务受到牵连，目前有两种处理方式

   1.代码上优化：大任务拆分为小任务，小任务之间增加休眠期，比如每100条sleep 1秒，让cpu做到雨露均沾；

   2.限制pod的资源占用，limit cpu 等，降低pod相互影响，一次业务应用被一个基础服务影响，一看监控该基础服务几乎跑满宿主机的cpu

- fullgc频繁导致长时间STW，前端大量超时，看下某客户环境猖狂的gc log

```
2021-11-01T01:41:28.604+0000: 1460.617: [Full GC (Allocation Failure) 2021-11-01T01:41:28.604+0000: 1460.617: [Tenured: 2097151K->2097151K(2097152K), 2.3259098 secs] 3040895K->2417455K(3040896K), [Metaspace: 122544K->122544K(1163264K)], 2.3260359 secs] [Times: user=2.32 sys=0.01, real=2.32 secs]``2021-11-01T01:41:31.429+0000: 1463.442: [Full GC (Allocation Failure) 2021-11-01T01:41:31.429+0000: 1463.442: [Tenured: 2097151K->2097151K(2097152K), 3.0093385 secs] 3040246K->2392920K(3040896K), [Metaspace: 122575K->122575K(1163264K)], 3.0094839 secs] [Times: user=3.02 sys=0.02, real=3.01 secs]``2021-11-01T01:41:34.861+0000: 1466.874: [Full GC (Allocation Failure) 2021-11-01T01:41:34.861+0000: 1466.874: [Tenured: 2097151K->2097151K(2097152K), 2.4219892 secs] 3040364K->2397366K(3040896K), [Metaspace: 122590K->122590K(1163264K)], 2.4221382 secs] [Times: user=2.42 sys=0.00, real=2.42 secs]
```

每次持续时间2.5s左右，每次的开始几乎紧跟着上一次的结束，jvm基本干不了别的，全用来处理gc了，再看看arthas dashboard的监控，cpu几乎全让vm thread给占了

优化思路是设置合理的jvm内存，降低fullgc频率，具体设置方式如下：

![image-20220425194548382](media/image-20220425194548382.png)

图片内容来源于https://tech.meituan.com/2017/12/29/jvm-optimize.html

# 3 超时带来的连锁反应

客户为了打通内部信息化流程，会要求我们和其他系统做集成，比如待办同步到OA，业务数据同步到数据中台等，交互方式也是多种多样，http、webservice、直接写库等，因为这块相对于业务来讲比较独立，所以和外部的交互这块是外包出去的，负责人界限模糊，人员流动大等导致了“屎山堆积“，第一版的代码可能还会按照规范来写，到了第N版的时候就是怎么方便怎么来了，本应该异步的做了同步，本应该配置超时的就是不配置，正常的时候比谁都正常，出事的时候牵一发动全身，

怎么办呢，这种就只能指望重构了，异步化、检查超时等是否缺失，不能异步化的引入熔断降级等策略，