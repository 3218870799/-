某张表，每月以300乘以200乘以30等于180万的数量增加，而且基数还在持续增加中，且该表维护的数据很多，列已经横向拆分了三张表，每张表大约50个列左右已经；

拆表的目标：

1：将大表的数据拆分到各个分表，保证每张表的数据量在1000万左右；

2：对各个接口进行优化，保证接口对内外的可用性；

难点：

1：基础表，涉及的东西多，场景多；

2：数据量大，迁移数据过程必须保证系统稳定；分表功能上线时，必须尽量压缩系统无法使用时长，同时需要保证系统可用性。这要求团队必须设计完整可靠的上线流程、数据迁移方案、回滚方案、降级策略。

选型：

采用sharding-jdbc作为分表插件：

优势：

支持多种分片逻辑，自动识别=或in判断具体在哪张分表里；

轻量级，作为maven依赖引入即可，对业务侵入性低；



分表的依据：

垂直分表其实已经相当于做过了，主要进行的是横向分表；因为与日期与强关系，所以根据净值日期分表最合适不过了，因为他一定会出现，查询频繁，其他字段，比如公司，产品ID也可，但是公司的话有些公司不均匀，产品的话太多，



技术难点：

**多数据源事务问题**



sharding-jdbc在使用的时候是需要用自己的独立数据源的，那么就难免出现多数据源事务问题。



这个我们通过自定义注解，自定义切面开启事务，通过方法栈逐层回滚or提交的方式解决的。



**多表的分页问题**



拆表一定会引起分页查询的难度增加。由于各个表查出来的数据量不等，原始的sql语句limit不再适用，需要设计一个新方法便捷的获取分页信息。

在此介绍一个分页的思路供大家参考

综合考虑业务实际与开发的复杂程度，项目团队决定在出现跨表查询的情况下，每一张表采用一个线程进行查询，以提高查询效率。



这个方案的难点在于分页规则的转换。例如，页面传入的offset和pageSize分别为8和20。各分表中符合条件的数量分别为10,10,50。那么我们需要将总的分页条件转化为三个分表各自的分页条件，如图



![图片](https://mmbiz.qpic.cn/mmbiz/R5ic1icyNBNd7kACl27HUrTwUGv5uWVCpFTgppqccKLV7Wiacic5PHeNJa9UM5k0zQqTz4uWMPSO8MfuaH8G52SgXg/640?wx_fmt=other&wxfrom=5&wx_lazy=1&wx_co=1)



通过上图可以看到，大分页条件(offset=8,pageSize=20)，转换为(offset=8,pageSize=2)，(offset=0.pageSize=10)，(offset=0,pageSize=8)三个条件。

整个计算过程如下：

1) 多线程查询各个分表中满足条件的数据数量

2) 将各个表数量按照分表的先后顺序累加，形成图 8的数轴

3) 判断第一条数据和最后一条数据所在的表

4) 除第一条和最后一条数据所在表外，其他表offset=0，pageSize=总数量

5) 计算第一条数据的offset，pageSize

计算最后一条数据的pageSize，同时将该表查询条件的offset设置为0



**数据迁移方案**



在数据迁移前，团队讨论过两套迁移方案：



1)请DBA迁移数据；

2)手写代码迁移数据，他们各有自己的优缺点：



![图片](https://mmbiz.qpic.cn/mmbiz_png/R5ic1icyNBNd7kACl27HUrTwUGv5uWVCpF5gLywTwVCicUZu6nZjicQXiaEsMpPicM2iaSDb9PKwF9CqVSUAFKBXAsDWQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



综合考虑时间成本和对线上数据库的影响，团队决定采用两种方案结合的方式：



- 交易时间为三个月前的冷数据，由于更新几率不大，采用代码的方式迁移，人为控制每次迁移数量，少量多次，蚂蚁搬家；
- 交易时间为三个月内的热数据，由于会在上线前频繁出现更新操作，则在上线前停止写操作，而后由DBA整体迁移。这样将时间成本平摊到平时，上线前只有约2个小时左右迁移数据时系统无法使用。
- 同时，除了最后一次DBA迁移数据外，能够人为控制每次迁移的数据量，整体避免数据库实例级别的高延迟。



整体上线流程



为保证新表拆分功能的稳定性和大表下线的稳定，团队将整个项目分为三个阶段：



- **第一阶段：**建立分表，大表数据迁移分表，线上数据新表老表双写，所有查询走分表（验证观察）
- **第二阶段：**停止写老数据表，其他业务直连数据库改为资金提供对外接口（验证观察）
- 第三阶段：大表下线

